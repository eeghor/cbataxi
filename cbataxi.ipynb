{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available Data\n",
    "\n",
    "The **trip**-related dat apoints are the following:\n",
    "\n",
    "* 'medallion',\n",
    "* ' hack_license',\n",
    "* ' vendor_id',\n",
    "* ' rate_code',\n",
    "* ' store_and_fwd_flag',\n",
    "* ' pickup_datetime',\n",
    "* ' dropoff_datetime',\n",
    "* ' passenger_count',\n",
    "* ' trip_time_in_secs',\n",
    "* ' trip_distance',\n",
    "* ' pickup_longitude',\n",
    "* ' pickup_latitude',\n",
    "* ' dropoff_longitude',\n",
    "* ' dropoff_latitude'\n",
    "\n",
    "and the **fare** CSV file contains the columns as below\n",
    "\n",
    "* 'medallion',\n",
    "* ' hack_license',\n",
    "* ' vendor_id',\n",
    "* ' pickup_datetime',\n",
    "* ' payment_type',\n",
    "* ' fare_amount',\n",
    "* ' surcharge',\n",
    "* ' mta_tax',\n",
    "* ' tip_amount',\n",
    "* ' tolls_amount',\n",
    "* ' total_amount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.\tWhat is the distribution of number of passengers per trip?\n",
    "b.\tWhat is the distribution of payment_type?\n",
    "c.\tWhat is the distribution of fare amount?\n",
    "d.\tWhat is the distribution of tip amount?\n",
    "e.\tWhat is the distribution of total amount?\n",
    "f.\tWhat are top 5 busiest hours of the day?\n",
    "g.\tWhat are the top 10 busiest locations of the city?\n",
    "h.\tWhich trip has the highest standard deviation of travel time?\n",
    "i.\tWhich trip has most consistent fares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taxi:\n",
    "    \n",
    "    def __init__(self, trip_file, fare_file):\n",
    "        \n",
    "        self.trip_file = trip_file\n",
    "        self.fare_file = fare_file\n",
    "        \n",
    "        self.distros = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    def get_distro(self, rows_at_once=10000):\n",
    "        \n",
    "        # trip is defined by (medallion, pickup_datetime)\n",
    "        \n",
    "        for i, d in enumerate(pd.read_csv('data/' + self.trip_file, chunksize=rows_at_once, \n",
    "                                          usecols=['medallion', ' pickup_datetime', ' passenger_count'])):\n",
    "            for row in d.groupby(['medallion', ' pickup_datetime']).sum().iterrows():\n",
    "                self.distros['passengers'][row[0]] += row[1][' passenger_count']\n",
    "                \n",
    "            if i%10 == 0:\n",
    "                print(f'done {i*rows_at_once:,} rows..')\n",
    "        \n",
    "        for i, d in enumerate(pd.read_csv('data/' + self.fare_file, chunksize=rows_at_once,\n",
    "                                          usecols=['medallion', ' pickup_datetime', ' payment_type', ' fare_amount', ' tip_amount'])):\n",
    "            for row in d.groupby(['medallion', ' pickup_datetime']).sum().iterrows():\n",
    "                \n",
    "                self.distros['payment_type'][row[0]] += row[1][' payment_type']\n",
    "                self.distros['fare_amount'][row[0]] += row[1][' fare_amount']\n",
    "                self.distros['tip_amount'][row[0]] += row[1][' tip_amount']\n",
    "                \n",
    "            if i%10 == 0:\n",
    "                print(f'done {i*rows_at_once:,} rows..')\n",
    "                \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0 rows..\n",
      "done 100,000 rows..\n",
      "done 200,000 rows..\n",
      "done 300,000 rows..\n",
      "done 400,000 rows..\n",
      "done 500,000 rows..\n",
      "done 600,000 rows..\n",
      "done 700,000 rows..\n",
      "done 800,000 rows..\n",
      "done 900,000 rows..\n",
      "done 1,000,000 rows..\n",
      "done 1,100,000 rows..\n",
      "done 1,200,000 rows..\n",
      "done 1,300,000 rows..\n",
      "done 1,400,000 rows..\n",
      "done 1,500,000 rows..\n",
      "done 1,600,000 rows..\n",
      "done 1,700,000 rows..\n",
      "done 1,800,000 rows..\n",
      "done 1,900,000 rows..\n",
      "done 2,000,000 rows..\n",
      "done 2,100,000 rows..\n",
      "done 2,200,000 rows..\n",
      "done 2,300,000 rows..\n",
      "done 2,400,000 rows..\n",
      "done 2,500,000 rows..\n",
      "done 2,600,000 rows..\n",
      "done 2,700,000 rows..\n",
      "done 2,800,000 rows..\n",
      "done 2,900,000 rows..\n",
      "done 3,000,000 rows..\n",
      "done 3,100,000 rows..\n",
      "done 3,200,000 rows..\n",
      "done 3,300,000 rows..\n",
      "done 3,400,000 rows..\n",
      "done 3,500,000 rows..\n",
      "done 3,600,000 rows..\n",
      "done 3,700,000 rows..\n",
      "done 3,800,000 rows..\n",
      "done 3,900,000 rows..\n",
      "done 4,000,000 rows..\n",
      "done 4,100,000 rows..\n",
      "done 4,200,000 rows..\n",
      "done 4,300,000 rows..\n",
      "done 4,400,000 rows..\n",
      "done 4,500,000 rows..\n",
      "done 4,600,000 rows..\n",
      "done 4,700,000 rows..\n",
      "done 4,800,000 rows..\n",
      "done 4,900,000 rows..\n",
      "done 5,000,000 rows..\n",
      "done 5,100,000 rows..\n",
      "done 5,200,000 rows..\n",
      "done 5,300,000 rows..\n",
      "done 5,400,000 rows..\n",
      "done 5,500,000 rows..\n",
      "done 5,600,000 rows..\n",
      "done 5,700,000 rows..\n",
      "done 5,800,000 rows..\n",
      "done 5,900,000 rows..\n",
      "done 6,000,000 rows..\n",
      "done 6,100,000 rows..\n",
      "done 6,200,000 rows..\n",
      "done 6,300,000 rows..\n",
      "done 6,400,000 rows..\n",
      "done 6,500,000 rows..\n",
      "done 6,600,000 rows..\n",
      "done 6,700,000 rows..\n",
      "done 6,800,000 rows..\n",
      "done 6,900,000 rows..\n",
      "done 7,000,000 rows..\n",
      "done 7,100,000 rows..\n",
      "done 7,200,000 rows..\n",
      "done 7,300,000 rows..\n",
      "done 7,400,000 rows..\n",
      "done 7,500,000 rows..\n",
      "done 7,600,000 rows..\n",
      "done 7,700,000 rows..\n",
      "done 7,800,000 rows..\n",
      "done 7,900,000 rows..\n",
      "done 8,000,000 rows..\n",
      "done 8,100,000 rows..\n",
      "done 8,200,000 rows..\n",
      "done 8,300,000 rows..\n",
      "done 8,400,000 rows..\n",
      "done 8,500,000 rows..\n",
      "done 8,600,000 rows..\n",
      "done 8,700,000 rows..\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    tx = Taxi(trip_file='trip_data_4.csv', fare_file='trip_fare_4.csv').get_distro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
